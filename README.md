# Translation
This is the 2nd homework for DL course teached by GeLi Professor

references:
Attention Is All Your Need
http://nlp.seas.harvard.edu/2018/04/03/attention.html

In this project, I realized a neural translation machine used Transformer model.
Part of the code about model architecture comes from the blog in the references list.

The dataset is downloaded from here:
http://www.manythings.org/anki/

This is a small dataset. So we can see that there exist wrong entities translation errors in case study while syntax are mostly correct.

Most detail can be seen in report folder.

Thanks!!
